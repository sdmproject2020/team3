{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# つくレポ数が多いレシピの特徴を抽出する。\n",
    "まずは個々の料理ではなく、全体的な特徴をみる.\n",
    "\n",
    "つくレポ数を従属変数、料理名の頻出単語（記号も含む）を説明変数として主成分分析を行い、影響の大きな特徴を抜き出す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 料理名の頻出単語と頻出記号を導出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Iterator, TextIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import csv\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上位20位の単語をみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('/usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "tagger.parse('')\n",
    "\n",
    "def main(place):\n",
    "    \"\"\"\n",
    "    コマンドライン引数で指定したディレクトリ内のファイルを読み込んで、頻出単語を表示する\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "\n",
    "    year = []\n",
    "    for i in range(1998, 2015):\n",
    "        year.append(i)\n",
    "\n",
    "    for i in year:\n",
    "        df = pd.read_csv(f'/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/recipe/recipe{i}.csv', names=[\"dish_name\"], usecols=[2])\n",
    "        # 欠損値を補完する\n",
    "        df[\"dish_name\"].fillna(\"non-data\", inplace=True)\n",
    "\n",
    "        # データのクレンジングを行う。\n",
    "        df[\"dish_name\"].replace(\" \", \"\", inplace=True) # 半角スペースを消去する\n",
    "        df[\"dish_name\"].replace(\"　\", \"\", inplace=True) # 全角スペースを消去する\n",
    "        df[\"dish_name\"].replace(\"〜\", \"ー\", inplace=True) # 伸ばす棒の〜をーに統一する。\n",
    "\n",
    "        print(f'{i}:')\n",
    "\n",
    "        frequency = Counter()\n",
    "\n",
    "        frequency = count_words(df[\"dish_name\"])\n",
    "\n",
    "        words = []\n",
    "        for word, count in frequency.most_common(place):\n",
    "            words.append(word)\n",
    "            # print(word, count)\n",
    "        word_list.append(words)\n",
    "    return word_list\n",
    "\n",
    "def count_words(data):\n",
    "    frequency = Counter()\n",
    "\n",
    "    for content in data:\n",
    "        words = get_words(content) # 料理名に含まれる名詞のリストを取得する。\n",
    "        # Counterのupdate()メソッドにリストなどの反復可能オブジェクトを指定すると、\n",
    "        # リストに含まれる値の出現回数を一度に増やせる\n",
    "        frequency.update(words)\n",
    "\n",
    "    print(f'Found {len(frequency)} words from {len(data)} dishes.\\n')\n",
    "    return frequency\n",
    "\n",
    "def get_words(content):\n",
    "    \"\"\"\n",
    "    文字列内に出現するのリスト（重複含む）を取得する関数\n",
    "    \"\"\"\n",
    "\n",
    "    words = []\n",
    "    node = tagger.parseToNode(content)\n",
    "    while node:\n",
    "        words.append(node.surface)\n",
    "        node = node.next\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1998:\n\nFound 139 words from 43 dishes.\n1999:\n\nFound 702 words from 353 dishes.\n2000:\n\nFound 3660 words from 4499 dishes.\n2001:\n\nFound 6315 words from 9836 dishes.\n2002:\n\nFound 7888 words from 13118 dishes.\n2003:\n\nFound 10197 words from 19973 dishes.\n2004:\n\nFound 10291 words from 21410 dishes.\n2005:\n\nFound 10392 words from 23897 dishes.\n2006:\n\nFound 15277 words from 47212 dishes.\n2007:\n\nFound 24546 words from 106840 dishes.\n2008:\n\nFound 28672 words from 144512 dishes.\n2009:\n\nFound 34575 words from 204316 dishes.\n2010:\n\nFound 37108 words from 219530 dishes.\n2011:\n\nFound 34965 words from 200210 dishes.\n2012:\n\nFound 38837 words from 252121 dishes.\n2013:\n\nFound 37360 words from 235464 dishes.\n2014:\n\nFound 34914 words from 212138 dishes.\n"
    }
   ],
   "source": [
    "word_list = main(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全ての年で空欄が1位となってしまっているので、それを削除し、csvファイルに書き込んで可視化する。\n",
    "word_list = np.delete(word_list, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nwith open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\", \"a\") as f:\\n    writer = csv.writer(f)\\n    writer.writerows(word_list)\\nwith open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\") as f:\\n    print(f.read())\\n'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "with open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\", \"a\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(word_list)\n",
    "with open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "！や★といった記号が多用されていた。\n",
    "次は名詞に絞って調べてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_noun(place):\n",
    "    \"\"\"\n",
    "    コマンドライン引数で指定したディレクトリ内のファイルを読み込んで、頻出単語を表示する\n",
    "    \"\"\"\n",
    "    word_list_noun = []\n",
    "\n",
    "    year = []\n",
    "    for i in range(1998, 2015):\n",
    "        year.append(i)\n",
    "\n",
    "    for i in year:\n",
    "        df = pd.read_csv(f'/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/recipe/recipe{i}.csv', names=[\"dish_name\"], usecols=[2])\n",
    "        # 欠損値を補完する\n",
    "        df[\"dish_name\"].fillna(\"non-data\", inplace=True)\n",
    "\n",
    "        # データのクレンジングを行う。（できてない）\n",
    "        df[\"dish_name\"].replace(\" \", \"\", inplace=True) # 半角スペースを消去する\n",
    "        df[\"dish_name\"].replace(\"　\", \"\", inplace=True) # 全角スペースを消去する\n",
    "        df[\"dish_name\"].replace(\"〜\", \"ー\", inplace=True) # 伸ばす棒の〜をーに統一する。\n",
    "\n",
    "        print(f'{i}:')\n",
    "\n",
    "        frequency = Counter()\n",
    "\n",
    "        frequency = count_words_noun(df[\"dish_name\"])\n",
    "\n",
    "        words = []\n",
    "        for word, count in frequency.most_common(place):\n",
    "            words.append(word)\n",
    "        word_list_noun.append(words)\n",
    "    return word_list_noun\n",
    "\n",
    "def count_words_noun(data):\n",
    "    frequency = Counter()\n",
    "\n",
    "    for content in data:\n",
    "        words = get_words_noun(content) # 料理名に含まれる名詞のリストを取得する。\n",
    "        # Counterのupdate()メソッドにリストなどの反復可能オブジェクトを指定すると、\n",
    "        # リストに含まれる値の出現回数を一度に増やせる\n",
    "        frequency.update(words)\n",
    "\n",
    "    print(f'Found {len(frequency)} nouns from {len(data)} dishes.\\n')\n",
    "    return frequency\n",
    "\n",
    "def get_words_noun(content):\n",
    "    \"\"\"\n",
    "    文字列内に出現する名詞のリスト（重複含む）を取得する関数\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    node = tagger.parseToNode(content)\n",
    "    while node:\n",
    "        # node.featureはカンマで区切られた文字列なので、split()で分割して\n",
    "        # 最初の2項目をposとpos_sub1に代入する。posはPart of Speech（品詞）の略\n",
    "        pos = node.feature.split(',')[0]\n",
    "        if pos == '名詞':\n",
    "            words.append(node.surface)\n",
    "        node = node.next\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1998:\nFound 99 nouns from 43 dishes.\n\n1999:\nFound 559 nouns from 353 dishes.\n\n2000:\nFound 3040 nouns from 4499 dishes.\n\n2001:\nFound 5419 nouns from 9836 dishes.\n\n2002:\nFound 6784 nouns from 13118 dishes.\n\n2003:\nFound 8770 nouns from 19973 dishes.\n\n2004:\nFound 8936 nouns from 21410 dishes.\n\n2005:\nFound 9039 nouns from 23897 dishes.\n\n2006:\nFound 13422 nouns from 47212 dishes.\n\n2007:\nFound 21887 nouns from 106840 dishes.\n\n2008:\nFound 25673 nouns from 144512 dishes.\n\n2009:\nFound 31367 nouns from 204316 dishes.\n\n2010:\nFound 33825 nouns from 219530 dishes.\n\n2011:\nFound 31699 nouns from 200210 dishes.\n\n2012:\nFound 35343 nouns from 252121 dishes.\n\n2013:\nFound 33964 nouns from 235464 dishes.\n\n2014:\nFound 31524 nouns from 212138 dishes.\n\n"
    }
   ],
   "source": [
    "word_list_noun = main_noun(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "﻿料理名での頻出単語上位20位,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,\nの,サラダ,て,、,焼き,！,煮,肉,簡単,リゾット,紅茶,お,に,＆,豆腐,た,で,ホイル,パン,。\nの,と,簡単,！,サラダ,風,煮,炒め,揚げ,。,焼き,　,た,で,トマト,な,、,チーズ,お,スープ\nの,と,！,簡単,風,サラダ,♪,煮,・,　,焼き,炒め,お,で,☆,スープ,ケーキ,トマト,揚げ,（\nの,と,♪,！,☆,簡単,煮,サラダ,風,★,で,炒め,　,・,焼き,お,ケーキ,）,（,豆腐\nの,と,！,☆,簡単,♪,サラダ,★,で,　,風,～,煮,お,炒め,・,焼き,）,ケーキ,（\nの,と,！,☆,で,♪,簡単,　,サラダ,煮,風,お,★,。,炒め,・,焼き,ケーキ,）,（\nの,と,☆,！,簡単,♪,で,　,★,サラダ,お,・,煮,風,炒め,。,ケーキ,）,（,焼き\nの,と,☆,！,♪,で,簡単,★,　,サラダ,煮,お,風,）,炒め,ケーキ,（,焼き,・,～\nの,☆,と,♪,！,簡単,で,★,サラダ,　,お,煮,炒め,風,焼き,に,ケーキ,豆腐,～,・\nの,☆,と,♪,！,簡単,で,★,お,サラダ,　,炒め,に,煮,風,焼き,～,・,豆腐,ケーキ\nの,☆,と,♪,簡単,で,！,★,お,　,サラダ,に,炒め,焼き,風,煮,～,✿,♡,・\nの,☆,と,簡単,♪,！,で,★,お,　,に,サラダ,炒め,焼き,風,煮,～,野菜,トマト,豆腐\nの,☆,と,簡単,♪,で,！,★,お,に,　,炒め,サラダ,風,焼き,煮,＊,チーズ,野菜,豆腐\nの,☆,と,簡単,で,♪,！,に,お,★,　,サラダ,炒め,＊,焼き,風,煮,チーズ,野菜,トマト\nの,と,☆,簡単,で,！,♪,お,に,サラダ,炒め,★,塩,＊,焼き,　,風,煮,麹,野菜\nの,と,簡単,☆,！,で,♪,に,お,♡,サラダ,炒め,焼き,＊,風,★,煮,　,野菜,トマト\nの,と,簡単,☆,！,で,♪,♡,に,お,炒め,サラダ,焼き,風,★,煮,＊,トマト,野菜,鶏\n,,,,,,,,,,,,,,,,,,,\n料理名での頻出名詞上位20位,,,,,,,,,,,,,,,,,,,サラダ,焼き,肉,簡単,リゾット,紅茶,豆腐,ホイル,パン,豚,角,スペシャル,ピーマン,詰め,チーズ,ぎもち,口,あたり,ショコラ・グラッセ,ベｰグルサンド\n簡単,サラダ,風,焼き,トマト,チーズ,スープ,鶏,ポテト,～,鶏肉,マリネ,ケーキ,豚,揚げ,大根,野菜,バナナ,トースト,ごはん\n簡単,風,サラダ,♪,焼き,スープ,ケーキ,トマト,大根,ソース,豆腐,～,鶏,チーズ,野菜,パスタ,カレー,チキン,肉,豚肉\n♪,簡単,サラダ,風,焼き,ケーキ,豆腐,スープ,トマト,チーズ,鶏,大根,ソース,～,揚げ,∽∽,豚,野菜,風味,中華\n簡単,♪,サラダ,風,～,焼き,ケーキ,トマト,豆腐,スープ,鶏,ソース,チーズ,パン,野菜,パスタ,大根,豚,カレー,風味\n♪,簡単,サラダ,風,ケーキ,焼き,～,豆腐,スープ,トマト,鶏,野菜,チーズ,ソース,パン,大根,カレー,風味,豚,卵\n簡単,♪,サラダ,風,ケーキ,焼き,～,豆腐,スープ,パン,鶏,トマト,豚,チーズ,野菜,ソース,パスタ,大根,カレー,味噌\n♪,簡単,サラダ,風,ケーキ,焼き,～,豆腐,トマト,スープ,鶏,パン,野菜,チーズ,豚,大根,ソース,パスタ,入り,クッキー\n♪,簡単,サラダ,風,焼き,ケーキ,豆腐,～,鶏,トマト,パン,チーズ,野菜,大根,スープ,豚,カレー,ソース,パスタ,肉\n♪,簡単,サラダ,風,～,焼き,豆腐,ケーキ,♡,トマト,チーズ,鶏,大根,野菜,豚,パン,パスタ,スープ,カレー,ソース\n♪,簡単,サラダ,風,焼き,～,✿,♡,豆腐,野菜,トマト,鶏,チーズ,カレー,ケーキ,パスタ,大根,スープ,パン,豚\n簡単,♪,サラダ,風,焼き,～,野菜,トマト,豆腐,鶏,♡,✿,チーズ,大根,豚,スープ,ケーキ,パスタ,カレー,パン\n簡単,♪,サラダ,風,焼き,チーズ,野菜,豆腐,～,鶏,✿,トマト,♡,肉,パスタ,豚,カレー,大根,スープ,弁当\n簡単,♪,サラダ,風,焼き,チーズ,野菜,トマト,♡,豆腐,～,鶏,スープ,✿,大根,肉,豚,ケーキ,パン,パスタ\n簡単,♪,サラダ,塩,焼き,風,麹,野菜,♡,トマト,鶏,チーズ,豆腐,肉,スープ,豚,～,パスタ,大根,卵\n簡単,♪,♡,サラダ,風,焼き,野菜,トマト,鶏,豆腐,チーズ,肉,塩,スープ,豚,大根,弁当,卵,パスタ,カレー\n簡単,♪,♡,サラダ,風,焼き,トマト,野菜,鶏,豆腐,肉,塩,チーズ,豚,スープ,卵,パスタ,揚げ,カレー,大根\n\n"
    }
   ],
   "source": [
    "with open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\", \"a\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(word_list_noun)\n",
    "with open(\"/Users/tamuramasayuki/Desktop/3S/基礎プロジェクトB/programming/dataset/analysis/frequent_words.csv\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}